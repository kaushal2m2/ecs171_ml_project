{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stroke\n",
      "1    4861\n",
      "0    4861\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>work_type_0.0</th>\n",
       "      <th>work_type_1.0</th>\n",
       "      <th>work_type_2.0</th>\n",
       "      <th>work_type_3.0</th>\n",
       "      <th>work_type_4.0</th>\n",
       "      <th>Residence_type_0.0</th>\n",
       "      <th>Residence_type_1.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.816895</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.801265</td>\n",
       "      <td>0.301260</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.743652</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.679023</td>\n",
       "      <td>0.212981</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.975586</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.234512</td>\n",
       "      <td>0.254296</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.597168</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.536008</td>\n",
       "      <td>0.276060</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.963379</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.549349</td>\n",
       "      <td>0.156930</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender       age  hypertension  heart_disease  ever_married   \n",
       "0     1.0  0.816895             0              1           1.0  \\\n",
       "1     0.0  0.743652             0              0           1.0   \n",
       "2     1.0  0.975586             0              1           1.0   \n",
       "3     0.0  0.597168             0              0           1.0   \n",
       "4     0.0  0.963379             1              0           1.0   \n",
       "\n",
       "   avg_glucose_level       bmi  smoking_status  work_type_0.0  work_type_1.0   \n",
       "0           0.801265  0.301260             1.0              0              0  \\\n",
       "1           0.679023  0.212981             2.0              0              0   \n",
       "2           0.234512  0.254296             2.0              0              0   \n",
       "3           0.536008  0.276060             3.0              0              0   \n",
       "4           0.549349  0.156930             2.0              0              0   \n",
       "\n",
       "   work_type_2.0  work_type_3.0  work_type_4.0  Residence_type_0.0   \n",
       "0              1              0              0                   0  \\\n",
       "1              0              1              0                   1   \n",
       "2              1              0              0                   1   \n",
       "3              1              0              0                   0   \n",
       "4              0              1              0                   1   \n",
       "\n",
       "   Residence_type_1.0  \n",
       "0                   1  \n",
       "1                   0  \n",
       "2                   0  \n",
       "3                   1  \n",
       "4                   0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from IPython.display import display\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# load dataset\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "# drop the column id\n",
    "df = df.drop(columns=['id'])\n",
    "\n",
    "# Fill bmi with mean\n",
    "df['bmi'] = df['bmi'].fillna(df['bmi'].mean())\n",
    "\n",
    "# For each of the categorical attribtues, encode the set of categories to be 0 ~ (n_classes - 1)\n",
    "cats = ['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']\n",
    "encoder = OrdinalEncoder()\n",
    "df[cats] = encoder.fit_transform(df[cats])\n",
    "df = pd.get_dummies(df, columns = [\"work_type\", \"Residence_type\"], dtype=int) \n",
    "\n",
    "# normalize numerical data using the min-max normalization technique\n",
    "num = [\"age\", \"avg_glucose_level\", \"bmi\"]\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "df[num] = scaler.fit_transform(df[num])\n",
    "\n",
    "# Split data into features and target\n",
    "X = df.drop('stroke', axis=1)\n",
    "y = df['stroke']\n",
    "\n",
    "# Apply SMOTE only on training data\n",
    "smote = SMOTE(random_state=42)\n",
    "x_os, y_os = smote.fit_resample(X, y)\n",
    "print(y_os.value_counts())\n",
    "X.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.8656663029364868\n",
      "f1 = 0.8734046858076084\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(max_depth = 10, n_estimators = 14, random_state=42)\n",
    "\n",
    "CV = cross_validate(rf, x_os, y_os, cv=10, scoring=['accuracy', 'f1'])\n",
    "print('accuracy =', CV['test_accuracy'].mean())\n",
    "print('f1 =', CV['test_f1'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.7870814459543477\n",
      "f1 = 0.7962077909993641\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "cls = LogisticRegression(max_iter=1000)\n",
    "CV = cross_validate(cls, x_os, y_os, cv=10, scoring=['accuracy', 'f1'])\n",
    "print('accuracy =', CV['test_accuracy'].mean())\n",
    "print('f1 =', CV['test_f1'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.9017721272717276\n",
      "f1 = 0.906471194472276\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC(C = 100, gamma = 1, kernel = \"rbf\")\n",
    "CV = cross_validate(svc, x_os, y_os, cv=10, scoring=['accuracy', 'f1'])\n",
    "print('accuracy =', CV['test_accuracy'].mean())\n",
    "print('f1 =', CV['test_f1'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.8425234415642089\n",
      "f1 = 0.8522716060066087\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes = (15, 10), max_iter = 1000)\n",
    "CV = cross_validate(mlp, x_os, y_os, cv=10, scoring=['accuracy', 'f1'])\n",
    "print('accuracy =', CV['test_accuracy'].mean())\n",
    "print('f1 =', CV['test_f1'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.7272169565934554\n",
      "f1 = 0.7781942324493178\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb = GaussianNB(var_smoothing = 0.001)\n",
    "CV = cross_validate(gnb, x_os, y_os, cv=10, scoring=['accuracy', 'f1'])\n",
    "print('accuracy =', CV['test_accuracy'].mean())\n",
    "print('f1 =', CV['test_f1'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.7272169565934554\n",
      "f1 = 0.7781942324493178\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(metric = 'manhattan', n_neighbors = 3, weights = 'distance')\n",
    "CV = cross_validate(gnb, x_os, y_os, cv=10, scoring=['accuracy', 'f1'])\n",
    "print('accuracy =', CV['test_accuracy'].mean())\n",
    "print('f1 =', CV['test_f1'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.9330409746277052\n",
      "f1 = 0.9343115562116943\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "base_models = [\n",
    "    ('rf', RandomForestClassifier(max_depth = 10, n_estimators = 14, random_state=42)),  # Random Forest\n",
    "    ('cls', LogisticRegression(max_iter=1000)),  # Logistic Regression\n",
    "    ('svc', SVC(C = 100, gamma = 1, kernel = \"rbf\")),  # SVM with linear kernel\n",
    "    ('gnb', GaussianNB(var_smoothing = 0.001)),  # Gaussian Naive Bayes\n",
    "    ('knn', KNeighborsClassifier(metric = 'manhattan', n_neighbors = 3, weights = 'distance')),  # k-Nearest Neighbors\n",
    "    ('mlp', MLPClassifier(hidden_layer_sizes = (15, 10), max_iter = 1000))  # Multilayer Perceptron\n",
    "]\n",
    "final_estimator = RandomForestClassifier(max_depth = 10, n_estimators = 14, random_state=42)\n",
    "stacking_classifier = StackingClassifier(estimators=base_models, final_estimator=final_estimator)\n",
    "CV = cross_validate(stacking_classifier, x_os, y_os, cv=10, scoring=['accuracy', 'f1'])\n",
    "print('accuracy =', CV['test_accuracy'].mean())\n",
    "print('f1 =', CV['test_f1'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "rf = RandomForestClassifier(max_depth = 10, n_estimators = 14, random_state=42)\n",
    "cls = LogisticRegression(max_iter=1000)\n",
    "svc = SVC(C = 100, gamma = 1, kernel = \"rbf\")\n",
    "mlp = MLPClassifier(hidden_layer_sizes = (15, 10), max_iter = 1000)\n",
    "gnb = GaussianNB(var_smoothing = 0.001)\n",
    "knn = KNeighborsClassifier(metric = 'manhattan', n_neighbors = 3, weights = 'distance')\n",
    "base_models = [\n",
    "    ('rf', RandomForestClassifier(max_depth = 10, n_estimators = 14, random_state=42)),  # Random Forest\n",
    "    ('cls', LogisticRegression(max_iter=1000)),  # Logistic Regression\n",
    "    ('svc', SVC(C = 100, gamma = 1, kernel = \"rbf\")),  # SVM with linear kernel\n",
    "    ('gnb', GaussianNB(var_smoothing = 0.001)),  # Gaussian Naive Bayes\n",
    "    ('knn', KNeighborsClassifier(metric = 'manhattan', n_neighbors = 3, weights = 'distance')),  # k-Nearest Neighbors\n",
    "    ('mlp', MLPClassifier(hidden_layer_sizes = (15, 10), max_iter = 1000))  # Multilayer Perceptron\n",
    "]\n",
    "final_estimator = RandomForestClassifier(max_depth = 10, n_estimators = 14, random_state=42)\n",
    "stacking_classifier = StackingClassifier(estimators=base_models, final_estimator=final_estimator)\n",
    "#fitting\n",
    "rf = rf.fit(x_os,y_os)\n",
    "cls = cls.fit(x_os,y_os)\n",
    "svc = svc.fit(x_os,y_os)\n",
    "mlp = mlp.fit(x_os,y_os)\n",
    "gnb = gnb.fit(x_os,y_os)\n",
    "knn = knn.fit(x_os,y_os)\n",
    "stacking_classifier = stacking_classifier.fit(x_os,y_os)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['encoder/encoder.joblib']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "\n",
    "dump(rf, 'models/rf_model.joblib')\n",
    "dump(cls, 'models/cls_model.joblib')\n",
    "dump(svc, 'models/svc_model.joblib')\n",
    "dump(mlp, 'models/mlp_model.joblib')\n",
    "dump(gnb, 'models/gnb_model.joblib')\n",
    "dump(knn, 'models/knn_model.joblib')\n",
    "dump(stacking_classifier, 'models/stacking_classifier_model.joblib')\n",
    "\n",
    "dump(scaler, 'scaler/scaler.joblib')\n",
    "\n",
    "dump(encoder, 'encoder/encoder.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workplace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
